---
title: "Full Likelihood EIV Model (Vectorized + Analytical Gradients Only)"
author: "aishell"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Simulation
```{r simulate}
simulate_eiv_data <- function(n, beta, sigma_eta = 0.3, mu_x = -0.7, tau_x = 0.3, mu_y = -0.7, tau_y = 0.3) {
  x_true <- rnorm(n, 0, 1)
  eta <- rnorm(n, 0, sigma_eta)
  y_true <- beta * x_true + eta
  s_x <- rlnorm(n, mu_x, tau_x)
  s_y <- rlnorm(n, mu_y, tau_y)
  x_obs <- x_true + rnorm(n, 0, s_x)
  y_obs <- y_true + rnorm(n, 0, s_y)
  data.frame(x_obs, y_obs, s_x, s_y)
}

set.seed(123)
true_beta <- 2.0
true_sigma_eta <- 0.3
n <- 2000
dat <- simulate_eiv_data(n, true_beta, true_sigma_eta)
```

---

## Vectorized full likelihood with analytical gradients
```{r vectorized_grad}
loglik_full_vec_grad <- function(par, data) {
  beta <- par[1]
  sigma_eta2 <- exp(par[2])
  x <- data$x_obs; y <- data$y_obs
  sx2 <- data$s_x^2; sy2 <- data$s_y^2
  n <- length(x)

  a11 <- 1 + sx2
  a12 <- rep(beta, n)
  a22 <- beta^2 + sigma_eta2 + sy2
  detS <- a11 * a22 - a12^2

  Sinv11 <-  a22 / detS
  Sinv22 <-  a11 / detS
  Sinv12 <- -a12 / detS

  q <- Sinv11 * x^2 + 2 * Sinv12 * x * y + Sinv22 * y^2
  ll <- -0.5 * sum(log(detS) + q)

  # Derivatives of Σ wrt beta and sigma_eta2
  dS_db_11 <- rep(0, n)
  dS_db_12 <- rep(1, n)
  dS_db_22 <- 2 * beta
  dS_ds_11 <- rep(0, n)
  dS_ds_12 <- rep(0, n)
  dS_ds_22 <- rep(1, n)

  # Trace terms tr(Sinv * dS/dθ)
  trA_db <- Sinv11 * dS_db_11 + 2 * Sinv12 * dS_db_12 + Sinv22 * dS_db_22
  trA_ds <- Sinv11 * dS_ds_11 + 2 * Sinv12 * dS_ds_12 + Sinv22 * dS_ds_22

  # (x,y)A dS A(x,y)' terms
  Ax <- Sinv11 * x + Sinv12 * y
  Ay <- Sinv12 * x + Sinv22 * y

  tmp_db <- dS_db_11 * Ax^2 + 2 * dS_db_12 * Ax * Ay + dS_db_22 * Ay^2
  tmp_ds <- dS_ds_11 * Ax^2 + 2 * dS_ds_12 * Ax * Ay + dS_ds_22 * Ay^2

  grad_beta <- 0.5 * sum(tmp_db - trA_db)
  grad_sigma <- 0.5 * sum(tmp_ds - trA_ds)

  attr(ll, 'gradient') <- c(grad_beta, grad_sigma)
  ll
}
```

---

## Fit the model
```{r fit}
negloglik_vec_grad <- function(par, data) {
  val <- -loglik_full_vec_grad(par, data)
  attr(val, 'gradient') <- -attr(val, 'gradient')
  val
}

fit_full <- function(fn, data) {
  start <- c(1, log(var(data$y_obs)))
  system.time({ opt <- optim(start, fn, data = data, method='BFGS', hessian=TRUE) }) -> t
  list(par = opt$par, time = t['elapsed'], ll = -opt$value)
}

res <- fit_full(negloglik_vec_grad, dat)
```

---

## Summary
```{r summary}
cat(sprintf('True β = %.3f\nEstimated β = %.3f\nTrue σ_eta² = %.3f\nEstimated σ_eta² = %.3f\nLogLik = %.2f\nTime (s) = %.2f\n',
            true_beta, res$par[1], true_sigma_eta^2, exp(res$par[2]), res$ll, res$time))
```

---


---

## Gradient verification (multiple points)
```{r gradcheck}
if (!requireNamespace('numDeriv', quietly = TRUE)) install.packages('numDeriv', repos='https://cloud.r-project.org')
library(numDeriv)

# Define parameter points to test
test_points <- rbind(
  c(1, log(var(dat$y_obs))),
  res$par,
  c(res$par[1] - 0.5, res$par[2] - 0.3),
  c(res$par[1] + 0.5, res$par[2] + 0.3),
  c(res$par[1] * 0.8, res$par[2] * 1.2)
)
rownames(test_points) <- c('Start','MLE','Low','High','Scaled')

compare_grad <- function(p) {
  num <- grad(function(q) -loglik_full_vec_grad(q, dat), p)
  ana <- -attr(loglik_full_vec_grad(p, dat), 'gradient')
  data.frame(Numerical = num, Analytical = ana, Diff = num - ana)
}

grad_results <- lapply(1:nrow(test_points), function(i) {
  p <- test_points[i,]
  data.frame(Point = rownames(test_points)[i], Parameter = c('beta','log_sigma_eta2'), compare_grad(p))
})

grad_table <- do.call(rbind, grad_results)
grad_table
```
EOF2
